---
title: "Analyzing 2022 NFL 4th Down Success by Team"
author: "Jack Miller and Alex Jackson"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, 
                      message = FALSE)
```

```{r packages, include = FALSE}
library(nflfastR)
library(tidyverse)
library(ggrepel)
library(nflplotR)
library(knitr)
library(broom)
library(xgboost)
library(caTools)
library(caret)
library(glmnet)
library(ggpmisc)
library(patchwork)
```

```{r load data, echo = FALSE}
data_99 <- nflfastR::load_pbp(1999) %>% 
  mutate(year = 1999)
data_00 <- nflfastR::load_pbp(2000) %>% 
  mutate(year = 2000)
data_01 <- nflfastR::load_pbp(2001) %>% 
  mutate(year = 2001)
data_02 <- nflfastR::load_pbp(2002) %>% 
  mutate(year = 2002)
data_03 <- nflfastR::load_pbp(2003) %>% 
  mutate(year = 2003)
data_04 <- nflfastR::load_pbp(2004) %>% 
  mutate(year = 2004)
data_05 <- nflfastR::load_pbp(2005) %>% 
  mutate(year = 2005)
data_06 <- nflfastR::load_pbp(2006) %>% 
  mutate(year = 2006)
data_07 <- nflfastR::load_pbp(2007) %>% 
  mutate(year = 2007)
data_08 <- nflfastR::load_pbp(2008) %>% 
  mutate(year = 2008)
data_09 <- nflfastR::load_pbp(2009) %>% 
  mutate(year = 2009)
data_10 <- nflfastR::load_pbp(2010) %>% 
  mutate(year = 2010)
data_11 <- nflfastR::load_pbp(2011) %>% 
  mutate(year = 2011)
data_12 <- nflfastR::load_pbp(2012) %>% 
  mutate(year = 2012)
data_13 <- nflfastR::load_pbp(2013) %>% 
  mutate(year = 2013)
data_14 <- nflfastR::load_pbp(2014) %>% 
  mutate(year = 2014)
data_15 <- nflfastR::load_pbp(2015) %>% 
  mutate(year = 2015)
data_16 <- nflfastR::load_pbp(2016) %>% 
  mutate(year = 2016)
data_17 <- nflfastR::load_pbp(2017) %>% 
  mutate(year = 2017)
data_18 <- nflfastR::load_pbp(2018) %>% 
  mutate(year = 2018)
data_19 <- nflfastR::load_pbp(2019) %>% 
  mutate(year = 2019)
data_20 <- nflfastR::load_pbp(2020) %>% 
  mutate(year = 2020)
data_21 <- nflfastR::load_pbp(2021) %>% 
  mutate(year = 2021)
data_22 <- nflfastR::load_pbp(2022) %>% 
  mutate(year = 2022)
data <- rbind(data_99, data_00, data_01, data_02, data_03, data_04, data_05, 
              data_06, data_07, data_08, data_09, data_10, data_11, data_12,
              data_13, data_14, data_15, data_16, data_17, data_18, data_19,
              data_20, data_21, data_22)
```

```{r clean data, echo = FALSE}
data_main <- data %>% 
  mutate(pos_team_epa = ifelse(posteam == home_team, total_home_epa, total_away_epa)) %>% 
  select(yardline_100, game_seconds_remaining, qtr, 
         down, ydstogo, score_differential, no_score_prob, 
         opp_fg_prob, opp_safety_prob, opp_td_prob, fg_prob, safety_prob, 
         td_prob, wp, fourth_down_converted, fourth_down_failed,
         posteam_timeouts_remaining, defteam_timeouts_remaining, ep, epa, year, 
         week, posteam, posteam_type, play_type, wpa) %>%
  filter(down == 4) %>% 
  mutate(play_type = as.factor(ifelse(play_type == "run" | play_type == "pass", "go", play_type))) %>% 
  drop_na(play_type, wpa) %>% 
  filter(play_type %in% c("go", "field_goal", "punt"))

punt_data <- data_main %>% 
  filter(play_type == "punt" & yardline_100 >= 30) %>% 
  select(-c(down, fourth_down_converted, fourth_down_failed, ep, epa, year,
            week, posteam, play_type, posteam_type)) %>% 
  select(wpa, everything())

kick_data <- data_main %>% 
  filter(play_type == "field_goal" & yardline_100 <= 50) %>% 
  select(-c(down, fourth_down_converted, fourth_down_failed, ep, epa, year,
            week, posteam, play_type, posteam_type)) %>% 
  select(wpa, everything())

go_data <- data_main %>% 
  filter(play_type == "go") %>% 
  select(-c(down, fourth_down_failed, ep, epa, year,
            week, posteam, play_type, posteam_type)) %>% 
  select(wpa, everything())
```

# Introduction

Teams across the National Football League have been incorporating analytics into their decision making more and more over the past 20 years. The emergence of analytics has been increasingly dragged by those who think football and numbers should stay separate. Recently, the decision to go for 2 points after scoring a touchdown to go down 6 instead of 7 points late in the game has become a controversy, yet it is an analytically-correct move. We believe the next enhancement of the game in regards to the incorporation of analytics comes one 4th-down decision making. Our project examines NFL 4th down decision making using play-by-play data dating back to 1999. Our goal is to build three models that predict expected win probability added for each of the three decisions coaches have on fourth downs: kick a field goal, punt it, or go for it. Personally, we believe teams should be going for it more and punting less than how they operate currently, but we wish ti support this claim with models.

For the purpose of our study, we simplified 4th down decision making, meaning we did not differentiate between run or pass plays, and any trick plays were included as going for it (i.e. lining up in punt formation does not classify it as a punt). To train our data, we used everything that was available to us. Our data comes from the `nflfastR` package which contains data on every play dating back to 1999. After filtering for 4th down plays, we used everything from this season all the way back to 1999. Although we considered basing our project on more recent data, we figured the more data the better and decided to use it all. 

# Exploratory Data Analysis

```{r play type counts, echo = FALSE}
data_main %>% 
  group_by(play_type) %>% 
  summarize(count = n(), 
            mean_wpa = mean(wpa)) %>% 
  kable(digits = 5)
```

```{r fig.width=4, fig.height=3, fig.align='center', echo = FALSE}
ggplot(data_main, aes(x=year)) + geom_line(aes(fill=..count.., color = play_type), stat="bin", binwidth= 1) +
  scale_x_continuous(breaks = c(1999:2021), labels = c(1999:2021), limits = c(1999, 2021)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust=1),
        panel.grid.minor.x = element_blank()) +
  labs(title = "Count of NFL 4th Down Plays",
       subtitle = "4th Down Plays Between 1999 and 2022",
       x = "Year", y = "# of Plays",
       color = "Decision")
```

To get a better idea of what our data looks like, we first wanted to see how much data of each type of play we have.
Most 4th down plays are punts, of course, and only a small piece of our dataset is go for it plays, which also makes sense. Looking at the graph however, we can see an uptick in go attempts and a steady decrease in punts over the last 4 full seasons. This hints at the greater picture we are trying to discover: coaches haven't found the right go/punt/kick balance. But they are trending in the right direction. 

```{r count by decision, echo = FALSE, fig.width=3, fig.height=4, fig.align='center'}
a <- ggplot(data_main, aes(x = wpa, color = play_type)) +
  geom_density() +
  labs(title = "WPA Density Plots",
       subtitle = "By Play Type",
       x = "WPA", y = "Density") +
  guides(color=guide_legend(title="Play Type"))
b <- ggplot(go_data, aes(x = wpa, color = as.factor(fourth_down_converted))) +
  geom_density() +
  labs(title = "Going for It WPA Density Plots",
       subtitle = "By 4th Down Converted",
       x = "WPA", y = "Density") +
  guides(color=guide_legend(title="4th Converted"))
a / b
```

We can also see that while most of the density plots for WPA are relatively normal, the density plot for going for it on 4th down appears slightly bimodal. This is because a successful 4th down conversion usually leads to a bigger change in WPA than a 4th down failed attempt. While we weren't sure if this was worthy of transforming WPA for the go for it model or all the models, it is something to beware of moving forward.

# Modeling

The goal with our models is to create the best possible models for predicting WPA (win probability added) given a certain game state. To do this, we trained 3 separate xGBoost models, each on their own data of one play type. We began by training a baseline xgboost model as well as a Lasso and Ridge regression model for each play type. After examining the MSEs of the models, the xgboost baseline model performed much better than both the ridge and lasso optimal models. After we decided to use xgboost for our final model, we played around with the parameters of the model to try and achieve the best predictive model possible.

[section on the reason we chose xgboost] We split the data for each model into train and test sets using 70-30 splits and then attempted to minimize the RMSE through adjusting model parameters. We also tested lasso and ridge regression models, just to make sure we were fitting the best possible type of model. 

### Punt Model

```{r punt xgboost, fig.width=4, fig.height=3, fig.align='center', include = FALSE}
set.seed(12321)
sample <- sample(c(TRUE, FALSE), nrow(punt_data), replace = TRUE, prob = c(0.7, 0.3))
punt_data_train <- punt_data[sample, ]
punt_data_test <- punt_data[!sample, ]
punt_train_x <- data.matrix(punt_data_train[, -1])
punt_train_y <- punt_data_train$wpa
punt_test_x <- data.matrix(punt_data_test[, -1])
punt_test_y <- punt_data_test$wpa
punt_xgb_train = xgb.DMatrix(data = punt_train_x, label = punt_train_y)
punt_xgb_test = xgb.DMatrix(data = punt_test_x, label = punt_test_y)
punt_watchlist = list(train=punt_xgb_train, test=punt_xgb_test)
punt_model = xgb.train(data = punt_xgb_train, max_depth = 8,  colsample_bylevel = 1, colsample_bytree = 1, watchlist=punt_watchlist, nrounds = 1000, verbose = 0, eta = 0.05, subsample = 0.6, lambda = 1, early_stopping_rounds = 10)
punt_model_xgboost = xgboost(data = punt_xgb_train, max_depth = 8,  colsample_bylevel = 1, colsample_bytree = 1, nrounds = 257, verbose = 0, eta = 0.05, subsample = 0.6, lambda = 1)
punt_pred_y = predict(punt_model_xgboost, punt_xgb_test)
print(paste("XG Boost RMSE:", RMSE(punt_test_y, punt_pred_y)))

plot(y=punt_test_y, x=punt_pred_y)
abline(lm(punt_test_y ~ punt_pred_y), col = "blue")
punt_res = data.frame(test_y= punt_test_y, pred_y = punt_pred_y, res = (punt_test_y-punt_pred_y), punt_test_x)
plot(punt_res$yardline_100, punt_res$res)
abline(0,0, col="blue")
```

```{r punt lasso, include = FALSE}
grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(punt_train_x, punt_train_y, alpha = 0, lambda = grid)
plot(lasso.mod)
cv.out <- cv.glmnet(punt_train_x, punt_train_y, alpha = 0)
plot(cv.out)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s = bestlam, newx = punt_test_x)
print(paste("Lasso RMSE:", RMSE(punt_test_y, lasso.pred)))
```

```{r punt ridge, include = FALSE}
ridge.mod <- glmnet(punt_train_x, punt_train_y, alpha = 0, lambda = grid, 
                    thresh = 1e-12)
ridge.pred <- predict(ridge.mod, s = 4, newx = punt_test_x)
print(paste("Ridge RMSE:", RMSE(punt_test_y, ridge.pred)))
```

Our optimal punt XG Boost model has a RMSE of 0.0216, which is the lowest RMSE we obtained throughout our XG Boost, Lasso, and Ridge Regression modelling process. Therefore, we will continue with this as our punt WPA model.

### Kick Model

```{r kick xgboost, fig.width=4, fig.height=3, fig.align='center', include = FALSE}
set.seed(12321)
sample <- sample(c(TRUE, FALSE), nrow(kick_data), replace = TRUE, prob = c(0.7, 0.3))
kick_data_train <- kick_data[sample, ]
kick_data_test <- kick_data[!sample, ]
kick_train_x <- data.matrix(kick_data_train[, -1])
kick_train_y <- kick_data_train$wpa
kick_test_x <- data.matrix(kick_data_test[, -1])
kick_test_y <- kick_data_test$wpa
kick_xgb_train = xgb.DMatrix(data = kick_train_x, label = kick_train_y)
kick_xgb_test = xgb.DMatrix(data = kick_test_x, label = kick_test_y)
kick_watchlist = list(train=kick_xgb_train, test=kick_xgb_test)
kick_model = xgb.train(data = kick_xgb_train, max_depth = 6,  colsample_bylevel = 1, colsample_bytree = 1, watchlist=kick_watchlist, nrounds = 1000, verbose = 0, eta = 0.1, subsample = 0.9)
kick_model_xgboost = xgboost(data = kick_xgb_train, max_depth = 6,  colsample_bylevel = 1, colsample_bytree = 1, nrounds = 1000, verbose = 0, eta = 0.1, subsample = 0.9)
kick_pred_y = predict(kick_model_xgboost, kick_xgb_test)
print(paste("XG Boost RMSE:", RMSE(kick_test_y, kick_pred_y)))

plot(y=kick_test_y, x=kick_pred_y)
abline(lm(kick_test_y ~ kick_pred_y), col = "blue")
kick_res = data.frame(test_y= kick_test_y, pred_y = kick_pred_y, res = (kick_test_y-kick_pred_y), kick_test_x)
plot(kick_res$yardline_100, kick_res$res)
abline(0,0, col="blue")
```

```{r kick lasso, include = FALSE}
lasso.mod.kick <- glmnet(kick_train_x, kick_train_y, alpha = 0, lambda = grid)
plot(lasso.mod.kick)
cv.out.kick <- cv.glmnet(kick_train_x, kick_train_y, alpha = 0)
plot(cv.out.kick)
bestlam <- cv.out.kick$lambda.min
lasso.pred.kick <- predict(lasso.mod.kick, s = bestlam, newx = kick_test_x)
print(paste("Lasso RMSE:", RMSE(kick_test_y, lasso.pred.kick)))
```

```{r kick ridge, include = FALSE}
ridge.mod.kick <- glmnet(kick_train_x, kick_train_y, alpha = 0, lambda = grid, 
                    thresh = 1e-12)
ridge.pred.kick <- predict(ridge.mod.kick, s = 4, newx = kick_test_x)
print(paste("Ridge RMSE:", RMSE(kick_test_y, ridge.pred.kick)))
```

Our optimal kick XG Boost model has a RMSE of 0.3921, which is the lowest RMSE we obtained throughout our XG Boost, Lasso, and Ridge Regression modelling process. Therefore, we will continue with this as our kick WPA model.

### Go Model

```{r go xgboost model, fig.width=4, fig.height=3, fig.align='center', include = FALSE}
go_data <- go_data %>% 
  select(-fourth_down_converted)

set.seed(12321)
sample <- sample(c(TRUE, FALSE), nrow(go_data), replace = TRUE, prob = c(0.7, 0.3))
go_data_train <- go_data[sample, ]
go_data_test <- go_data[!sample, ]
go_train_x <- data.matrix(go_data_train[, -1])
go_train_y <- go_data_train$wpa
go_test_x <- data.matrix(go_data_test[, -1])
go_test_y <- go_data_test$wpa
go_xgb_train = xgb.DMatrix(data = go_train_x, label = go_train_y)
go_xgb_test = xgb.DMatrix(data = go_test_x, label = go_test_y)
go_watchlist = list(train=go_xgb_train, test=go_xgb_test)
go_model = xgb.train(data = go_xgb_train, max_depth = 8,  colsample_bylevel = 1, colsample_bytree = 1, watchlist=go_watchlist, nrounds = 500, verbose = 0, eta = 0.05, subsample = 0.7)
go_model_xgboost = xgboost(data = go_xgb_train, max_depth = 6,  colsample_bylevel = 1, colsample_bytree = 1, nrounds = 60, verbose = 0, eta = 0.1, subsample = 0.9)
go_pred_y = predict(go_model_xgboost, go_xgb_test)
print(paste("XG Boost RMSE:", RMSE(go_test_y, go_pred_y)))

plot(y=go_test_y, x=go_pred_y)
abline(lm(go_test_y ~ go_pred_y), col = "blue")
go_res = data.frame(test_y= go_test_y, pred_y = go_pred_y, res = (go_test_y-go_pred_y), go_test_x)
plot(go_res$yardline_100, go_res$res)
abline(0,0, col="blue")
```

```{r go lasso, include =FALSE}
lasso.mod.go <- glmnet(go_train_x, go_train_y, alpha = 0, lambda = grid)
plot(lasso.mod.go)
cv.out.go <- cv.glmnet(go_train_x, go_train_y, alpha = 0)
plot(cv.out)
bestlam <- cv.out.go$lambda.min
lasso.pred.go <- predict(lasso.mod.go, s = bestlam, newx = go_test_x)
print(paste("Lasso RMSE:", RMSE(go_test_y, lasso.pred)))
```

```{r go ridge, include = FALSE}
ridge.mod.go <- glmnet(go_train_x, go_train_y, alpha = 0, lambda = grid, 
                    thresh = 1e-12)
ridge.pred.go <- predict(ridge.mod.go, s = 4, newx = go_test_x)
print(paste("Ridge RMSE:", RMSE(go_test_y, ridge.pred.go)))
```

Our optimal go for it XG Boost model has a RMSE of 0.5492, which is the lowest RMSE we obtained throughout our XG Boost, Lasso, and Ridge Regression modelling process. Therefore, we will continue with this as our go for it WPA model.

## Results

```{r echo = FALSE}
pred_data <- data_main %>% 
    select(-c(down, fourth_down_converted, fourth_down_failed, ep, epa, year,
            week, posteam, play_type, posteam_type)) %>% 
  select(wpa, everything())

data_x <- data.matrix(pred_data[, -1])
data_y <- pred_data$wpa
xgb_matrix = xgb.DMatrix(data = data_x, label = data_y)

ewpa_punt = predict(punt_model_xgboost, xgb_matrix)
ewpa_kick = predict(kick_model_xgboost, xgb_matrix)
ewpa_go = predict(go_model_xgboost, xgb_matrix)

pred_data <- pred_data %>% 
  mutate(yard_line = ifelse(yardline_100 > 50, -(100-yardline_100), yardline_100),
         game_minutes_remaining = paste0(trunc(game_seconds_remaining/60), ":", game_seconds_remaining%%60))

pred_data = cbind(pred_data, play_type = data_main$play_type, team = data_main$posteam, year = data_main$year, ewpa_punt, ewpa_kick, ewpa_go) %>% 
  mutate(
    #ewpa_punt = ifelse(yard_line < 31, -1, ewpa_punt),
         recommendation = case_when((ewpa_punt > ewpa_kick) & (ewpa_punt > ewpa_go) ~ "punt",
                                    (ewpa_kick > ewpa_punt) & (ewpa_kick > ewpa_go) ~ "field_goal",
                                    (ewpa_go > ewpa_kick) & (ewpa_go > ewpa_punt) ~ "go"),
         correct_call = ifelse(play_type == recommendation, "Yes", "No"),
         ewpa_max = pmax(ewpa_punt, ewpa_kick, ewpa_go),
         ewpa_play = case_when((play_type == "punt") ~ ewpa_punt,
                               (play_type == "field_goal") ~ ewpa_kick,
                               (play_type == "go") ~ ewpa_go),
         execution = wpa - ewpa_max)

pred_data$ewpa_max_percentile <- ecdf(pred_data$ewpa_max)(pred_data$ewpa_max)
pred_data$ewpa_play_percentile <- ecdf(pred_data$ewpa_max)(pred_data$ewpa_play)
pred_data$accuracy <- 100 * (1 - (pred_data$ewpa_max_percentile - pred_data$ewpa_play_percentile))
```

``` {r fig.width=4, fig.height=3, fig.align='center', echo = FALSE}

#pred_data %>% 
  #filter(correct_call == "No") %>% 
  #select(yard_line, game_minutes_remaining, ydstogo, score_differential, play_type, recommendation) 

#example <- confusionMatrix(data=predicted_value, reference = expected_value)
#example
ggplot(pred_data, aes(x = accuracy)) +
  geom_density()

pred_data %>% 
  filter(yard_line>0,
         year > 2020) %>% 
  ggplot(aes(x=yard_line, fill = play_type)) + geom_density(alpha=0.7)

pred_data %>% 
  filter(yard_line>0) %>% 
  ggplot(aes(x=yard_line, fill = recommendation)) + geom_histogram(binwidth = 1, alpha=.4, position="identity")
```

```{r echo = FALSE}
crucial_data <- data_main %>% 
  select(-c(down, fourth_down_converted, fourth_down_failed, ep, epa, year,
            week, posteam, play_type, posteam_type)) %>% 
  select(wpa, everything()) %>% 
  filter((yardline_100 < 51 | ydstogo < 5) & (abs(score_differential) < 14.5) & (wp > 0.1))

data_x <- data.matrix(crucial_data[, -1])
data_y <- crucial_data$wpa
xgb_matrix = xgb.DMatrix(data = data_x, label = data_y)

ewpa_punt = predict(punt_model_xgboost, xgb_matrix)
ewpa_kick = predict(kick_model_xgboost, xgb_matrix)
ewpa_go = predict(go_model_xgboost, xgb_matrix)

filtered_data <- data_main %>% 
  filter((yardline_100 < 51 | ydstogo < 5) & (abs(score_differential) < 14.5) & (wp > 0.1))

crucial_data <- cbind(crucial_data, play_type = filtered_data$play_type, 
          team = filtered_data$posteam, year = filtered_data$year, ewpa_punt, ewpa_kick, ewpa_go) %>% 
  mutate(recommendation = case_when((ewpa_punt > ewpa_kick) & (ewpa_punt > ewpa_go) ~ "punt",
                                    (ewpa_kick > ewpa_punt) & (ewpa_kick > ewpa_go) ~ "field_goal",
                                    (ewpa_go > ewpa_kick) & (ewpa_go > ewpa_punt) ~ "go"),
         correct_call = ifelse(play_type == recommendation, "Yes", "No"),
         ewpa_max = pmax(ewpa_punt, ewpa_kick, ewpa_go),
         ewpa_play = case_when((play_type == "punt") ~ ewpa_punt,
                               (play_type == "field_goal") ~ ewpa_kick,
                               (play_type == "go") ~ ewpa_go),
         execution = wpa - ewpa_max)

crucial_data$ewpa_max_percentile <- ecdf(crucial_data$ewpa_max)(crucial_data$ewpa_max)
crucial_data$ewpa_play_percentile <- ecdf(crucial_data$ewpa_max)(crucial_data$ewpa_play)
crucial_data$accuracy <- 100 * (1 - (crucial_data$ewpa_max_percentile - crucial_data$ewpa_play_percentile))
```

``` {r fig.width=4, fig.height=3, fig.align='center', echo = FALSE}
ggplot(crucial_data, aes(x = accuracy)) +
  geom_density()
```

``` {r echo = FALSE}
top_decisions <- crucial_data %>% 
  arrange(desc(execution)) %>% 
  select(ewpa_punt, ewpa_kick, ewpa_go, recommendation, play_type, wpa, execution, accuracy) %>%
  head(10)

crucial_data %>% 
  filter(yardline_100<51) %>% 
  ggplot(aes(x=yardline_100, fill = play_type)) + geom_histogram(binwidth = 1, alpha=.4, position="identity") +
  theme_bw()+
  labs(title = "Real Life Decisions", subtitle = "1999-2022, opponents' side of field, game within 14 points, win probability > 0.1", x="Yardline", y="Number of Plays", fill="Play Type")

crucial_data %>% 
  filter(yardline_100<51) %>% 
  ggplot(aes(x=yardline_100, fill = recommendation)) + geom_histogram(binwidth = 1, alpha=.4, position="identity") +
  theme_bw()+
  scale_y_continuous(limits = c(0,1000))+
  labs(title = "Model Recommended Decisions", subtitle = "1999-2022, opponents' side of field, game within 14 points, win probability > 0.1", x="Yardline", y="Number of Plays", fill="Play Type")
```

```{r echo = FALSE}
conf_mat_df <- crucial_data %>% 
  droplevels(c("no_play", "qb_kneel"))
recommendation = conf_mat_df$recommendation
play_type = conf_mat_df$play_type
conf_matrix <- tibble(play_type, recommendation)
table(conf_matrix) %>% 
  kable()
```


```{r echo = FALSE,  fig.width=4, fig.height=3, fig.align='center'}
ggplot(crucial_data, aes(x = accuracy, y = execution)) +
  geom_point() +
  stat_poly_line() +
  stat_poly_eq(aes(label = after_stat(eq.label))) +
  labs(title = "Accuracy vs. Execution of NFL Teams on 4th Down",
       x = "Accuracy", y = "Execution"
       )
```

```{r echo = FALSE}
top_decisions %>% 
  kable(digits = 3)
```

```{r fig.width=4, fig.height=3, fig.align='center', echo = FALSE}
ggplot(data_main, aes(x = wpa)) +
  geom_density()
```




```{r copy over, fig.width=4, fig.height=3, fig.align='center', echo = FALSE}
crucial_data %>% 
  filter(yardline_100<51) %>% 
  ggplot(aes(x=yardline_100, fill = play_type)) + geom_histogram(binwidth = 1, alpha=.4, position="identity") +
  theme_bw()+
  labs(title = "Real Life Decisions", subtitle = "1999-2022, opponents' side of field, game within 14 points, win probability > 0.1", x="Yardline", y="Number of Plays", fill="Play Type")

crucial_data %>% 
  filter(yardline_100<51) %>% 
  ggplot(aes(x=yardline_100, fill = recommendation)) + geom_histogram(binwidth = 1, alpha=.4, position="identity") +
  theme_bw()+
  scale_y_continuous(limits = c(0,1000))+
  labs(title = "Model Recommended Decisions", subtitle = "1999-2022, opponents' side of field, game within 14 points, win probability > 0.1", x="Yardline", y="Number of Plays", fill="Play Type")

pred_data %>% 
  group_by(yard_line, play_type) %>% 
  summarise(count = n())

pred_data %>% 
  mutate(ewpa_punt = ifelse((yard_line < 31) & (yard_line > 0), -1, ewpa_punt),
         ewpa_kick = ifelse(yard_line < 0, -1, ewpa_kick),
         recommendation = case_when((ewpa_punt > ewpa_kick) & (ewpa_punt > ewpa_go) ~ "punt",
                                    (ewpa_kick > ewpa_punt) & (ewpa_kick > ewpa_go) ~ "field_goal",
                                    (ewpa_go > ewpa_kick) & (ewpa_go > ewpa_punt) ~ "go")) %>% 
  filter(yardline_100<51) %>% 
  ggplot(aes(x=yardline_100, fill = recommendation)) + geom_histogram(binwidth = 1, alpha=.4, position="identity") +
  theme_bw()+
  scale_y_continuous(limits = c(0,1000))+
  labs(title = "Model Recommended Decisions", subtitle = "1999-2022, opponents' side of field, game within 14 points, win probability > 0.1", x="Yardline", y="Number of Plays", fill="Play Type")

pred_data %>% 
  filter(yard_line>0,
         year > 2020) %>% 
  ggplot(aes(x=yard_line, fill = play_type)) + geom_density(alpha=0.7)

pred_data %>% 
  filter(yard_line>0) %>% 
  ggplot(aes(x=yard_line, fill = recommendation)) + geom_histogram(binwidth = 1, alpha=.4, position="identity")
```

# Discussion and Conclusion

While our 
